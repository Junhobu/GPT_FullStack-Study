{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1,\n",
    "                  # GPT 응답 과정을 보이게 하는 과정\n",
    "                  # callback : LLM에 일어나는 events를 감지하는 방법\n",
    "                  streaming= True,\n",
    "                  callbacks=[StreamingStdOutCallbackHandler(),],\n",
    "                  \n",
    "                  )\n",
    "# PromptTemplate를 사용하는 이유 : prompttemplate를 디스크에 저장하고 load하기 위함\n",
    "# FewShot : 더 나은 대답을 위해 모델들에게 예제를 준다\n",
    "# ex) 고객지원 봇을 만들 경우 이미 고객과의 대화에서 입력한 답변을 가져와 더 나은 답변을 하도록 도움을 줄 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "      {\n",
    "            \"question\": \"What do you know about France?\",\n",
    "            \"answer\": \"\"\"\n",
    "            Here is what I know:\n",
    "            Capital: Paris\n",
    "            Language: French\n",
    "            Food: Wine and Cheese\n",
    "            Currency: Euro\n",
    "            \"\"\",\n",
    "      },\n",
    "      {\n",
    "            \"question\": \"What do you know about Italy?\",\n",
    "            \"answer\": \"\"\"\n",
    "            I know this:\n",
    "            Capital: Rome\n",
    "            Language: Italian\n",
    "            Food: Pizza and Pasta\n",
    "            Currency: Euro\n",
    "            \"\"\",\n",
    "      },\n",
    "      {\n",
    "            \"question\": \"What do you know about Greece?\",\n",
    "            \"answer\": \"\"\"\n",
    "            I know this:\n",
    "            Capital: Athens\n",
    "            Language: Greek\n",
    "            Food: Souvlaki and Feta Cheese\n",
    "            Currency: Euro\n",
    "            \"\"\",\n",
    "      },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n      Human: What do you know about France?\\n      AI: \\n            Here is what I know:\\n            Capital: Paris\\n            Language: French\\n            Food: Wine and Cheese\\n            Currency: Euro\\n            \\n\\n\\n\\n      Human: What do you know about Italy?\\n      AI: \\n            I know this:\\n            Capital: Rome\\n            Language: Italian\\n            Food: Pizza and Pasta\\n            Currency: Euro\\n            \\n\\n\\n\\n      Human: What do you know about Greece?\\n      AI: \\n            I know this:\\n            Capital: Athens\\n            Language: Greek\\n            Food: Souvlaki and Feta Cheese\\n            Currency: Euro\\n            \\n\\n\\nHuman: What do you know about Germany?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example을 사용하기 위한 형식 지정\n",
    "example_template = \"\"\"\n",
    "      Human: {question}\n",
    "      AI: {answer}\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "# 위와 동일\n",
    "# example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "      example_prompt = example_prompt,\n",
    "      examples=examples,\n",
    "      # 위 과정으로 랭체인이 알아서 각각의 예제들을 prompt를 사용하여 형식화함\n",
    "      # 사용자 질문이 어떻게 보여줄지 지정\n",
    "      # suffix : 형식화된 모든 예제 마지막에 나오는 내용\n",
    "      suffix = \"Human: What do you know about {country}?\",\n",
    "      input_variables = [\"country\"]\n",
    ")\n",
    "\n",
    "# 결과를 보면 위 예제와 같이 질문이 잘 작성됨을 알 수 있음\n",
    "prompt.format(country = \"Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "I know this:\n",
      "Capital: Seoul\n",
      "Language: Korean\n",
      "Food: Kimchi and Bibimbap\n",
      "Currency: South Korean Won"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\nI know this:\\nCapital: Seoul\\nLanguage: Korean\\nFood: Kimchi and Bibimbap\\nCurrency: South Korean Won')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\"country\" : \"Korea\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
